{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/alyssa-blair/csc-485B-group8/blob/main/csc485b_assignment1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dclGnLGAgbtH",
        "outputId": "1898278d-c983-485d-f8df-9707a42e474b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting git+https://github.com/andreinechaev/nvcc4jupyter.git\n",
            "  Cloning https://github.com/andreinechaev/nvcc4jupyter.git to /tmp/pip-req-build-_hpxp9ni\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/andreinechaev/nvcc4jupyter.git /tmp/pip-req-build-_hpxp9ni\n",
            "  Resolved https://github.com/andreinechaev/nvcc4jupyter.git to commit 28f872a2f99a1b201bcd0db14fdbc5a496b9bfd7\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Building wheels for collected packages: nvcc4jupyter\n",
            "  Building wheel for nvcc4jupyter (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for nvcc4jupyter: filename=nvcc4jupyter-1.2.1-py3-none-any.whl size=10743 sha256=3a570d3ab74e9051a615aa78d54722c78a69a0c83a1d407fccde14c37a30e96c\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-lg4djo7u/wheels/a8/b9/18/23f8ef71ceb0f63297dd1903aedd067e6243a68ea756d6feea\n",
            "Successfully built nvcc4jupyter\n",
            "Installing collected packages: nvcc4jupyter\n",
            "Successfully installed nvcc4jupyter-1.2.1\n",
            "Detected platform \"Colab\". Running its setup...\n",
            "Source files will be saved in \"/tmp/tmp8vy9aib7\".\n"
          ]
        }
      ],
      "source": [
        "# Load the extension that allows us to compile CUDA code in python notebooks\n",
        "# Documentation is here: https://nvcc4jupyter.readthedocs.io/en/latest/\n",
        "!pip install git+https://github.com/andreinechaev/nvcc4jupyter.git\n",
        "%load_ext nvcc4jupyter"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VVbDQthwogQF"
      },
      "outputs": [],
      "source": [
        "%%cuda_group_save -g \"source\" -n \"data_types.h\"\n",
        "/**\n",
        " * A collection of commonly used data types throughout this project.\n",
        " */\n",
        "#pragma once\n",
        "\n",
        "#include <stdint.h> // uint32_t\n",
        "\n",
        "using element_t = uint32_t;"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZqET4uI2ggwf"
      },
      "outputs": [],
      "source": [
        "%%cuda_group_save -g \"source\" -n \"cuda_common.h\"\n",
        "/**\n",
        " * Standard macros that can be useful for error checking.\n",
        " * https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__ERROR.html\n",
        " */\n",
        "#pragma once\n",
        "\n",
        "#include <cuda.h>\n",
        "\n",
        "#define CUDA_CALL(exp)                                       \\\n",
        "    do {                                                     \\\n",
        "        cudaError res = (exp);                               \\\n",
        "        if(res != cudaSuccess) {                             \\\n",
        "            printf(\"Error at %s:%d\\n %s\\n\",                  \\\n",
        "                __FILE__,__LINE__, cudaGetErrorString(res)); \\\n",
        "           exit(EXIT_FAILURE);                               \\\n",
        "        }                                                    \\\n",
        "    } while(0)\n",
        "\n",
        "#define CHECK_ERROR(msg)                                             \\\n",
        "    do {                                                             \\\n",
        "        cudaError_t err = cudaGetLastError();                        \\\n",
        "        if(cudaSuccess != err) {                                     \\\n",
        "            printf(\"Error (%s) at %s:%d\\n %s\\n\",                     \\\n",
        "                (msg), __FILE__, __LINE__, cudaGetErrorString(err)); \\\n",
        "            exit(EXIT_FAILURE);                                      \\\n",
        "        }                                                            \\\n",
        "    } while (0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GY0L7rKhoVaZ"
      },
      "outputs": [],
      "source": [
        "%%cuda_group_save -g \"source\" -n \"data_generator.h\"\n",
        "/**\n",
        " * Functions for generating random input data with a fixed seed\n",
        " */\n",
        "#pragma once\n",
        "\n",
        "#include <random>  // for std::mt19937, std::uniform_int_distribution\n",
        "#include <vector>\n",
        "\n",
        "#include \"data_types.h\"\n",
        "\n",
        "namespace csc485b {\n",
        "namespace a1 {\n",
        "\n",
        "/**\n",
        " * Generates and returns a vector of random uniform data of a given length, n,\n",
        " * for any integral type. Input range will be [0, 2n].\n",
        " */\n",
        "template < typename T >\n",
        "std::vector< T > generate_uniform( std::size_t n )\n",
        "{\n",
        "    // for details of random number generation, see:\n",
        "    // https://en.cppreference.com/w/cpp/numeric/random/uniform_int_distribution\n",
        "    std::size_t random_seed = 20240916;  // use magic seed\n",
        "    std::mt19937 rng( random_seed );     // use mersenne twister generator\n",
        "    std::uniform_int_distribution<> distrib(0, 2 * n);\n",
        "\n",
        "    std::vector< T > random_data( n ); // init array\n",
        "    std::generate( std::begin( random_data )\n",
        "                 , std::end  ( random_data )\n",
        "                 , [ &rng, &distrib ](){ return static_cast< T >( distrib( rng ) ); });\n",
        "\n",
        "    return random_data;\n",
        "}\n",
        "\n",
        "} // namespace a1\n",
        "} // namespace csc485b"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IJOKRZuCkDh2"
      },
      "outputs": [],
      "source": [
        "%%cuda_group_save -g \"source\" -n \"algorithm_choices.h\"\n",
        "#pragma once\n",
        "\n",
        "#include <vector>\n",
        "\n",
        "#include \"data_types.h\"\n",
        "\n",
        "namespace csc485b {\n",
        "namespace a1 {\n",
        "namespace cpu {\n",
        "\n",
        "void run_cpu_baseline( std::vector< element_t > data, std::size_t switch_at, std::size_t n );\n",
        "\n",
        "} // namespace cpu\n",
        "\n",
        "\n",
        "namespace gpu {\n",
        "\n",
        "void run_gpu_soln( std::vector< element_t > data, std::size_t switch_at, std::size_t n );\n",
        "\n",
        "} // namespace gpu\n",
        "} // namespace a1\n",
        "} // namespace csc485b"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V3lAuiBEhKjc"
      },
      "outputs": [],
      "source": [
        "%%cuda_group_save -g \"source\" -n \"cpu_baseline.cu\"\n",
        "/**\n",
        " * CPU methods that the GPU should outperform.\n",
        " */\n",
        "\n",
        "#include \"algorithm_choices.h\"\n",
        "\n",
        "#include <algorithm> // std::sort()\n",
        "#include <chrono>    // for timing\n",
        "#include <iostream>  // std::cout, std::endl\n",
        "\n",
        "namespace csc485b {\n",
        "namespace a1      {\n",
        "namespace cpu     {\n",
        "\n",
        "/**\n",
        " * Simple solution that just sorts the whole array with a built-in sort\n",
        " * function and then resorts the last portion in the opposing order with\n",
        " * a second call to that same built-in sort function.\n",
        " */\n",
        "void opposing_sort( element_t * data, std::size_t invert_at_pos, std::size_t num_elements )\n",
        "{\n",
        "    std::sort( data, data + num_elements, std::less< element_t >{} );\n",
        "    std::sort( data + invert_at_pos, data + num_elements, std::greater< element_t >{} );\n",
        "}\n",
        "\n",
        "/**\n",
        " * Run the single-threaded CPU baseline that students are supposed to outperform\n",
        " * in order to obtain higher grades on this assignment. Times the execution and\n",
        " * prints to the standard output (e.g., the screen) that \"wall time.\" Note that\n",
        " * the functions takes the input by value so as to not perturb the original data\n",
        " * in place.\n",
        " */\n",
        "void run_cpu_baseline( std::vector< element_t > data, std::size_t switch_at, std::size_t n )\n",
        "{\n",
        "    auto const cpu_start = std::chrono::high_resolution_clock::now();\n",
        "    opposing_sort( data.data(), switch_at, n );\n",
        "    auto const cpu_end = std::chrono::high_resolution_clock::now();\n",
        "\n",
        "    std::cout << \"CPU Baseline time: \"\n",
        "              << std::chrono::duration_cast<std::chrono::nanoseconds>(cpu_end - cpu_start).count()\n",
        "              << \" ns\" << std::endl;\n",
        "\n",
        "    for( auto const x : data ) std::cout << x << \" \"; std::cout << std::endl;\n",
        "}\n",
        "\n",
        "} // namespace cpu\n",
        "} // namespace a1\n",
        "} // namespace csc485b"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bjTbQ3EO2NwQ"
      },
      "outputs": [],
      "source": [
        "%%cuda_group_save -g \"source\" -n \"gpu_solution.cu\"\n",
        "/**\n",
        " * The file in which you will implement your GPU solutions!\n",
        " */\n",
        "\n",
        "#include \"algorithm_choices.h\"\n",
        "\n",
        "#include <chrono>    // for timing\n",
        "#include <iostream>  // std::cout, std::endl\n",
        "\n",
        "#include \"cuda_common.h\"\n",
        "\n",
        "namespace csc485b {\n",
        "namespace a1      {\n",
        "namespace gpu     {\n",
        "\n",
        "/**\n",
        " * The CPU baseline benefits from warm caches because the data was generated on\n",
        " * the CPU. Run the data through the GPU once with some arbitrary logic to\n",
        " * ensure that the GPU cache is warm too and the comparison is more fair.\n",
        " */\n",
        "__global__\n",
        "void warm_the_gpu( element_t * data, std::size_t invert_at_pos, std::size_t num_elements )\n",
        "{\n",
        "    int const th_id = blockIdx.x * blockDim.x + threadIdx.x;\n",
        "\n",
        "    // We know this will never be true, because of the data generator logic,\n",
        "    // but I doubt that the compiler will figure it out. Thus every element\n",
        "    // should be read, but none of them should be modified.\n",
        "    if( th_id < num_elements && data[ th_id ] > num_elements * 100 )\n",
        "    {\n",
        "        ++data[ th_id ]; // should not be possible.\n",
        "    }\n",
        "}\n",
        "\n",
        "/**\n",
        " * Your solution. Should match the CPU output.\n",
        " *\n",
        " * An implemnetation of the Bitonic Sort algorithm, where sorting order flips at invert_at_pos.\n",
        " */\n",
        "__global__\n",
        "void opposing_sort( element_t * data, std::size_t invert_at_pos, std::size_t num_elements )\n",
        "{\n",
        "    std::size_t const th_id = blockIdx.x * blockDim.x + threadIdx.x;\n",
        "\n",
        "    // Check that the thread id is within the number of elements\n",
        "    if( th_id < num_elements )\n",
        "    {\n",
        "        // Loop over the bitonic sequence length\n",
        "        for ( std::size_t sequence_len = 2; sequence_len <= num_elements; sequence_len <<= 1 )\n",
        "        {\n",
        "            // Loop over step sizes for this sequence length\n",
        "            for ( std::size_t step_size = sequence_len >> 1; step_size > 0; step_size >>= 1 )\n",
        "            {\n",
        "                // Calculate the position of the partner element\n",
        "                std::size_t position = th_id ^ step_size;\n",
        "                std::size_t sequence_num = th_id / sequence_len;\n",
        "\n",
        "                // Check that this thread, and it's partner are in the same sequence\n",
        "                if ( th_id < position && position < num_elements && sequence_num == (position / sequence_len) )\n",
        "                {\n",
        "                    // Determine sorting direction\n",
        "                    bool dir = sequence_num & 1 ^ ( sequence_len == num_elements && num_elements / step_size >= 4 && th_id >= invert_at_pos );\n",
        "\n",
        "                    // Check if the elements should be swapped\n",
        "                    if ( (data[th_id] < data[position]) == dir )\n",
        "                    {\n",
        "                        element_t tmp = data[ th_id ];\n",
        "                        data[ th_id ] = data[ position ];\n",
        "                        data[ position ] = tmp;\n",
        "                    }\n",
        "                }\n",
        "                __syncthreads();\n",
        "            }\n",
        "        }\n",
        "        return;\n",
        "    }\n",
        "}\n",
        "\n",
        "/**\n",
        " * Performs all the logic of allocating device vectors and copying host/input\n",
        " * vectors to the device. Times the opposing_sort() kernel with wall time,\n",
        " * but excludes set up and tear down costs such as mallocs, frees, and memcpies.\n",
        " */\n",
        "void run_gpu_soln( std::vector< element_t > data, std::size_t switch_at, std::size_t n )\n",
        "{\n",
        "    // Kernel launch configurations. Feel free to change these.\n",
        "    // This is set to maximise the size of a thread block on a T4, but it hasn't\n",
        "    // been tuned. It's not known if this is optimal.\n",
        "    std::size_t const threads_per_block = 1024;\n",
        "    std::size_t const num_blocks =  ( n + threads_per_block - 1 ) / threads_per_block;\n",
        "\n",
        "    // Allocate arrays on the device/GPU\n",
        "    element_t * d_data;\n",
        "    cudaMalloc( (void**) & d_data, sizeof( element_t ) * n );\n",
        "    CHECK_ERROR(\"Allocating input array on device\");\n",
        "\n",
        "    // Copy the input from the host to the device/GPU\n",
        "    cudaMemcpy( d_data, data.data(), sizeof( element_t ) * n, cudaMemcpyHostToDevice );\n",
        "    CHECK_ERROR(\"Copying input array to device\");\n",
        "\n",
        "    // Warm the cache on the GPU for a more fair comparison\n",
        "    warm_the_gpu<<< num_blocks, threads_per_block>>>( d_data, switch_at, n );\n",
        "\n",
        "    // Time the execution of the kernel that you implemented\n",
        "    auto const kernel_start = std::chrono::high_resolution_clock::now();\n",
        "    opposing_sort<<< num_blocks, threads_per_block>>>( d_data, switch_at, n );\n",
        "    auto const kernel_end = std::chrono::high_resolution_clock::now();\n",
        "    CHECK_ERROR(\"Executing kernel on device\");\n",
        "\n",
        "    // After the timer ends, copy the result back, free the device vector,\n",
        "    // and echo out the timings and the results.\n",
        "    cudaMemcpy( data.data(), d_data, sizeof( element_t ) * n, cudaMemcpyDeviceToHost );\n",
        "    CHECK_ERROR(\"Transferring result back to host\");\n",
        "    cudaFree( d_data );\n",
        "    CHECK_ERROR(\"Freeing device memory\");\n",
        "\n",
        "    std::cout << \"GPU Solution time: \"\n",
        "              << std::chrono::duration_cast<std::chrono::nanoseconds>(kernel_end - kernel_start).count()\n",
        "              << \" ns\" << std::endl;\n",
        "\n",
        "    for( auto const x : data ) std::cout << x << \" \"; std::cout << std::endl;\n",
        "}\n",
        "\n",
        "} // namespace gpu\n",
        "} // namespace a1\n",
        "} // namespace csc485b"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IRvVeK-QifnZ"
      },
      "outputs": [],
      "source": [
        "%%cuda_group_save -g \"source\" -n \"main.cu\"\n",
        "/**\n",
        " * Driver for the benchmark comparison. Generates random data,\n",
        " * runs the CPU baseline, and then runs your code.\n",
        " */\n",
        "\n",
        "#include <cstddef>  // std::size_t type\n",
        "#include <iostream> // std::cout, std::endl\n",
        "#include <vector>\n",
        "\n",
        "#include \"algorithm_choices.h\"\n",
        "#include \"data_generator.h\"\n",
        "#include \"data_types.h\"\n",
        "#include \"cuda_common.h\"\n",
        "\n",
        "int main()\n",
        "{\n",
        "    std::size_t const n = 1024;\n",
        "    std::size_t const switch_at = 3 * ( n >> 2 ) ;\n",
        "\n",
        "    auto data = csc485b::a1::generate_uniform< element_t >( n );\n",
        "    for( auto const x : data ) std::cout << x << \" \"; std::cout << std::endl;\n",
        "\n",
        "    csc485b::a1::cpu::run_cpu_baseline( data, switch_at, n );\n",
        "    csc485b::a1::gpu::run_gpu_soln( data, switch_at, n );\n",
        "\n",
        "    return EXIT_SUCCESS;\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S7F0eVsGjUNp",
        "outputId": "f855588a-8135-437b-8d39-4f31575dd0d3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "40 728 413 1246 1646 1668 1888 6 341 1632 351 212 1004 1116 1160 428 421 1778 1088 13 621 266 53 872 1048 236 326 608 865 316 1806 480 863 679 1337 1072 83 1026 1986 730 295 928 488 305 464 972 576 1064 1220 122 1227 1329 285 49 742 1146 761 1455 471 202 763 1616 1187 1052 1584 711 1453 998 1497 1290 992 1518 1953 616 1506 1998 932 1228 831 1616 922 1769 1652 2045 560 1955 790 1444 1773 682 1985 679 1072 693 238 1663 1946 1586 575 468 274 1137 1519 1493 71 780 1538 212 1010 480 334 1331 131 1957 754 199 430 1408 471 1685 1298 141 1501 719 1533 1386 767 1491 591 514 575 689 254 1650 1172 695 810 329 1459 150 654 483 1535 2026 110 1424 1378 315 101 555 815 1924 71 1328 485 942 1465 1323 1249 1109 1301 276 743 1283 768 374 221 1657 238 1635 1342 1680 1573 1725 1512 939 844 881 595 442 1409 2029 1558 1586 508 2003 955 1551 1413 698 179 1250 1522 836 2000 599 925 981 2040 1793 1909 1994 1767 1782 1467 1609 1220 990 1808 1483 65 1535 384 213 67 68 790 1394 1261 104 1845 443 559 1344 620 1131 1833 1002 1371 1483 232 1206 1614 1635 558 1240 19 1005 816 39 1479 883 116 1025 997 511 1076 1709 856 715 1263 1380 198 897 1339 287 942 1505 907 856 834 688 1782 1384 1827 1070 54 471 737 899 1426 784 1243 1259 1293 550 1499 1357 1079 1828 1507 1416 1319 177 325 1172 661 677 1920 674 1131 1270 444 1462 1014 793 829 996 975 1355 387 1102 1430 244 275 823 1657 2048 1819 417 41 951 1548 1154 499 752 1627 1167 1049 425 117 186 141 1061 1317 371 1759 120 345 395 1888 30 621 1966 1765 1553 1058 274 1904 1350 1929 607 1499 980 1696 1989 506 86 1772 593 1518 1731 1484 1854 1278 1816 438 1985 871 335 1823 1392 1429 1331 571 1361 144 811 614 1696 1822 1039 757 1061 565 1039 1424 170 1431 615 467 261 1324 1968 1722 118 1105 394 258 609 300 904 2006 206 643 1855 241 104 310 1118 1440 1066 1881 205 1766 1031 1081 381 260 1403 1441 1759 1301 260 1213 1779 465 2027 1746 701 2 1630 1990 1332 815 1288 1179 1257 713 759 1160 1959 1475 1095 345 83 1435 486 1388 1876 1494 1311 1489 208 1580 90 152 1980 150 41 785 709 804 955 358 59 1240 1934 591 260 254 1596 1742 1923 345 1806 473 1937 1343 729 1955 1589 552 1831 698 1857 1436 1387 354 155 1606 1012 1287 113 1268 1780 1727 1417 1440 22 54 698 640 1754 1961 1655 1325 559 1436 291 119 1542 542 1470 827 1954 440 955 1342 1864 806 1198 757 1130 2008 1310 1083 1708 1323 563 1283 1183 901 1572 297 512 585 430 1056 1861 1764 497 457 806 1701 1026 1029 1299 680 25 1588 548 1050 544 1539 1156 580 791 333 1349 1119 952 164 1621 49 1725 1739 1414 1776 1648 852 1693 256 1551 706 1749 1992 1248 1275 1852 1585 1493 1743 1584 1850 2012 1859 1192 1452 1822 1608 915 184 1389 1819 879 1435 1741 1739 1115 964 1631 80 1710 1777 1086 609 1751 193 5 1320 1437 1491 381 321 605 880 851 1480 1812 217 110 1137 884 286 1937 560 1903 245 1034 403 141 818 389 247 935 1481 732 454 662 1248 1855 1815 223 1645 75 1826 666 175 1081 1513 1386 898 1949 1745 1611 1013 104 1037 1505 612 1083 1501 248 535 1200 1385 1245 221 1454 1836 1416 698 239 661 1303 1339 596 1660 915 1182 394 868 386 1988 800 1019 750 1380 696 977 855 134 217 453 744 1406 1187 279 1948 299 1089 1084 860 1576 667 1659 1197 1219 1883 1038 1974 1036 326 1798 1833 552 859 799 2007 617 440 701 1086 1501 881 613 1133 443 1565 823 861 875 1950 1467 1630 1187 1158 2036 52 686 1226 67 836 1600 1483 124 167 21 1011 1621 1684 1322 173 467 1366 573 81 1169 386 937 778 999 1295 1606 524 1310 1601 1727 254 1111 7 41 1817 246 1167 926 667 1147 1864 947 707 1890 1196 1690 435 1557 1738 1622 1160 658 1520 228 1438 1672 1655 2006 522 410 35 99 654 1192 1639 2043 552 428 1926 1827 134 2043 1448 51 205 267 287 1015 541 1870 1998 156 181 757 1893 1708 1695 185 1654 1210 1836 883 1666 362 2045 1578 853 1262 398 1023 1782 678 702 574 1680 1273 1513 935 214 940 1169 985 987 1362 1334 1939 1646 317 1792 858 1192 1819 1706 787 176 419 1745 393 46 1536 21 1017 729 1051 1655 2037 1694 1817 401 1025 867 580 2018 1296 660 1349 533 210 1607 1099 1542 1528 1474 1849 1911 1376 905 924 1250 226 1761 1516 1461 978 460 904 790 601 1249 339 723 1374 1721 608 997 921 1141 726 391 908 1429 1333 1012 512 1094 1449 199 1552 985 1540 386 525 1502 609 1616 592 939 487 1531 1671 883 521 549 1272 632 20 1915 717 1281 939 1049 1493 218 923 1635 1248 284 52 59 1057 1154 303 1259 449 1613 1011 1862 1815 457 903 1179 1126 1284 2016 959 908 1191 172 1798 766 794 480 1324 1741 1149 322 1616 1655 1193 1956 339 1476 284 200 987 1647 306 1378 1183 1359 1926 201 1027 678 303 1600 791 1670 814 1194 705 866 312 76 1658 74 1652 510 1604 1099 1026 1678 443 408 1212 631 1122 1682 910 1370 758 1772 912 1749 349 \n",
            "CPU Baseline time: 66413 ns\n",
            "2 5 6 7 13 19 20 21 21 22 25 30 35 39 40 41 41 41 46 49 49 51 52 52 53 54 54 59 59 65 67 67 68 71 71 74 75 76 80 81 83 83 86 90 99 101 104 104 104 110 110 113 116 117 118 119 120 122 124 131 134 134 141 141 141 144 150 150 152 155 156 164 167 170 172 173 175 176 177 179 181 184 185 186 193 198 199 199 200 201 202 205 205 206 208 210 212 212 213 214 217 217 218 221 221 223 226 228 232 236 238 238 239 241 244 245 246 247 248 254 254 254 256 258 260 260 260 261 266 267 274 274 275 276 279 284 284 285 286 287 287 291 295 297 299 300 303 303 305 306 310 312 315 316 317 321 322 325 326 326 329 333 334 335 339 339 341 345 345 345 349 351 354 358 362 371 374 381 381 384 386 386 386 387 389 391 393 394 394 395 398 401 403 408 410 413 417 419 421 425 428 428 430 430 435 438 440 440 442 443 443 443 444 449 453 454 457 457 460 464 465 467 467 468 471 471 471 473 480 480 480 483 485 486 487 488 497 499 506 508 510 511 512 512 514 521 522 524 525 533 535 541 542 544 548 549 550 552 552 552 555 558 559 559 560 560 563 565 571 573 574 575 575 576 580 580 585 591 591 592 593 595 596 599 601 605 607 608 608 609 609 609 612 613 614 615 616 617 620 621 621 631 632 640 643 654 654 658 660 661 661 662 666 667 667 674 677 678 678 679 679 680 682 686 688 689 693 695 696 698 698 698 698 701 701 702 705 706 707 709 711 713 715 717 719 723 726 728 729 729 730 732 737 742 743 744 750 752 754 757 757 757 758 759 761 763 766 767 768 778 780 784 785 787 790 790 790 791 791 793 794 799 800 804 806 806 810 811 814 815 815 816 818 823 823 827 829 831 834 836 836 844 851 852 853 855 856 856 858 859 860 861 863 865 866 867 868 871 872 875 879 880 881 881 883 883 883 884 897 898 899 901 903 904 904 905 907 908 908 910 912 915 915 921 922 923 924 925 926 928 932 935 935 937 939 939 939 940 942 942 947 951 952 955 955 955 959 964 972 975 977 978 980 981 985 985 987 987 990 992 996 997 997 998 999 1002 1004 1005 1010 1011 1011 1012 1012 1013 1014 1015 1017 1019 1023 1025 1025 1026 1026 1026 1027 1029 1031 1034 1036 1037 1038 1039 1039 1048 1049 1049 1050 1051 1052 1056 1057 1058 1061 1061 1064 1066 1070 1072 1072 1076 1079 1081 1081 1083 1083 1084 1086 1086 1088 1089 1094 1095 1099 1099 1102 1105 1109 1111 1115 1116 1118 1119 1122 1126 1130 1131 1131 1133 1137 1137 1141 1146 1147 1149 1154 1154 1156 1158 1160 1160 1160 1167 1167 1169 1169 1172 1172 1179 1179 1182 1183 1183 1187 1187 1187 1191 1192 1192 1192 1193 1194 1196 1197 1198 1200 1206 1210 1212 1213 1219 1220 1220 1226 1227 1228 1240 1240 1243 1245 1246 1248 1248 1248 1249 1249 1250 1250 1257 1259 1259 1261 1262 1263 1268 1270 1272 1273 1275 1278 1281 1283 1283 1284 1287 1288 1290 1293 1295 1296 1298 1299 1301 1301 1303 1310 1310 1311 1317 1319 1320 1322 1323 1323 1324 1324 1325 1328 1329 1331 1331 1332 1333 1334 1337 1339 1339 1342 1342 1343 1344 1349 1349 1350 1355 1357 1359 1361 1362 1366 1370 1371 1374 1376 1378 1378 1380 1380 1384 1385 1386 1386 1387 1388 1389 1392 1394 1403 1406 1408 1409 1413 1414 1416 1416 1417 1424 1424 1426 1429 1429 1430 1431 1435 1435 1436 1436 1437 1438 1440 1440 1441 1444 1448 1449 1452 1453 1454 1455 1459 1461 1462 1465 1467 1467 1470 1474 1475 1476 1479 1480 1481 1483 1483 1483 1484 1489 1491 1491 1493 1493 1493 1494 1497 1499 1499 1501 1501 1501 1502 1505 1505 1506 1507 1512 1513 1513 1516 1518 2048 2045 2045 2043 2043 2040 2037 2036 2029 2027 2026 2018 2016 2012 2008 2007 2006 2006 2003 2000 1998 1998 1994 1992 1990 1989 1988 1986 1985 1985 1980 1974 1968 1966 1961 1959 1957 1956 1955 1955 1954 1953 1950 1949 1948 1946 1939 1937 1937 1934 1929 1926 1926 1924 1923 1920 1915 1911 1909 1904 1903 1893 1890 1888 1888 1883 1881 1876 1870 1864 1864 1862 1861 1859 1857 1855 1855 1854 1852 1850 1849 1845 1836 1836 1833 1833 1831 1828 1827 1827 1826 1823 1822 1822 1819 1819 1819 1817 1817 1816 1815 1815 1812 1808 1806 1806 1798 1798 1793 1792 1782 1782 1782 1780 1779 1778 1777 1776 1773 1772 1772 1769 1767 1766 1765 1764 1761 1759 1759 1754 1751 1749 1749 1746 1745 1745 1743 1742 1741 1741 1739 1739 1738 1731 1727 1727 1725 1725 1722 1721 1710 1709 1708 1708 1706 1701 1696 1696 1695 1694 1693 1690 1685 1684 1682 1680 1680 1678 1672 1671 1670 1668 1666 1663 1660 1659 1658 1657 1657 1655 1655 1655 1655 1654 1652 1652 1650 1648 1647 1646 1646 1645 1639 1635 1635 1635 1632 1631 1630 1630 1627 1622 1621 1621 1616 1616 1616 1616 1614 1613 1611 1609 1608 1607 1606 1606 1604 1601 1600 1600 1596 1589 1588 1586 1586 1585 1584 1584 1580 1578 1576 1573 1572 1565 1558 1557 1553 1552 1551 1551 1548 1542 1542 1540 1539 1538 1536 1535 1535 1533 1531 1528 1522 1520 1519 1518 \n",
            "GPU Solution time: 18301 ns\n",
            "2 5 6 7 13 19 20 21 21 22 25 30 35 39 40 41 41 41 46 49 49 51 52 52 53 54 54 59 59 65 67 67 68 71 71 74 75 76 80 81 83 83 86 90 99 101 104 104 104 110 110 113 116 117 118 119 120 122 124 131 134 134 141 141 141 144 150 150 152 155 156 164 167 170 172 173 175 176 177 179 181 184 185 186 193 198 199 199 200 201 202 205 205 206 208 210 212 212 213 214 217 217 218 221 221 223 226 228 232 236 238 238 239 241 244 245 246 247 248 254 254 254 256 258 260 260 260 261 266 267 274 274 275 276 279 284 284 285 286 287 287 291 295 297 299 300 303 303 305 306 310 312 315 316 317 321 322 325 326 326 329 333 334 335 339 339 341 345 345 345 349 351 354 358 362 371 374 381 381 384 386 386 386 387 389 391 393 394 394 395 398 401 403 408 410 413 417 419 421 425 428 428 430 430 435 438 440 440 442 443 443 443 444 449 453 454 457 457 460 464 465 467 467 468 471 471 471 473 480 480 480 483 485 486 487 488 497 499 506 508 510 511 512 512 514 521 522 524 525 533 535 541 542 544 548 549 550 552 552 552 555 558 559 559 560 560 563 565 571 573 574 575 575 576 580 580 585 591 591 592 593 595 596 599 601 605 607 608 608 609 609 609 612 613 614 615 616 617 620 621 621 631 632 640 643 654 654 658 660 661 661 662 666 667 667 674 677 678 678 679 679 680 682 686 688 689 693 695 696 698 698 698 698 701 701 702 705 706 707 709 711 713 715 717 719 723 726 728 729 729 730 732 737 742 743 744 750 752 754 757 757 757 758 759 761 763 766 767 768 778 780 784 785 787 790 790 790 791 791 793 794 799 800 804 806 806 810 811 814 815 815 816 818 823 823 827 829 831 834 836 836 844 851 852 853 855 856 856 858 859 860 861 863 865 866 867 868 871 872 875 879 880 881 881 883 883 883 884 897 898 899 901 903 904 904 905 907 908 908 910 912 915 915 921 922 923 924 925 926 928 932 935 935 937 939 939 939 940 942 942 947 951 952 955 955 955 959 964 972 975 977 978 980 981 985 985 987 987 990 992 996 997 997 998 999 1002 1004 1005 1010 1011 1011 1012 1012 1013 1014 1015 1017 1019 1023 1025 1025 1026 1026 1026 1027 1029 1031 1034 1036 1037 1038 1039 1039 1048 1049 1049 1050 1051 1052 1056 1057 1058 1061 1061 1064 1066 1070 1072 1072 1076 1079 1081 1081 1083 1083 1084 1086 1086 1088 1089 1094 1095 1099 1099 1102 1105 1109 1111 1115 1116 1118 1119 1122 1126 1130 1131 1131 1133 1137 1137 1141 1146 1147 1149 1154 1154 1156 1158 1160 1160 1160 1167 1167 1169 1169 1172 1172 1179 1179 1182 1183 1183 1187 1187 1187 1191 1192 1192 1192 1193 1194 1196 1197 1198 1200 1206 1210 1212 1213 1219 1220 1220 1226 1227 1228 1240 1240 1243 1245 1246 1248 1248 1248 1249 1249 1250 1250 1257 1259 1259 1261 1262 1263 1268 1270 1272 1273 1275 1278 1281 1283 1283 1284 1287 1288 1290 1293 1295 1296 1298 1299 1301 1301 1303 1310 1310 1311 1317 1319 1320 1322 1323 1323 1324 1324 1325 1328 1329 1331 1331 1332 1333 1334 1337 1339 1339 1342 1342 1343 1344 1349 1349 1350 1355 1357 1359 1361 1362 1366 1370 1371 1374 1376 1378 1378 1380 1380 1384 1385 1386 1386 1387 1388 1389 1392 1394 1403 1406 1408 1409 1413 1414 1416 1416 1417 1424 1424 1426 1429 1429 1430 1431 1435 1435 1436 1436 1437 1438 1440 1440 1441 1444 1448 1449 1452 1453 1454 1455 1459 1461 1462 1465 1467 1467 1470 1474 1475 1476 1479 1480 1481 1483 1483 1483 1484 1489 1491 1491 1493 1493 1493 1494 1497 1499 1499 1501 1501 1501 1502 1505 1505 1506 1507 1512 1513 1513 1516 1518 1518 1519 1520 1522 1528 1531 1533 1535 1535 1536 1538 1539 1540 1542 1542 1548 1551 1551 1552 1553 1557 1558 1565 1572 1573 1576 1578 1580 1584 1584 1585 1586 1586 1588 1589 1596 1600 1600 1601 1604 1606 1606 1607 1608 1609 1611 1613 1614 1616 1616 1616 1616 1621 1621 1622 1627 1630 1630 1631 1632 1635 1635 1635 1639 1645 1646 1646 1647 1648 1650 1652 1652 1654 1655 1655 1655 1655 1657 1657 1658 1659 1660 1663 1666 1668 1670 1671 1672 1678 1680 1680 1682 1684 1685 1690 1693 1694 1695 1696 1696 1701 1706 1708 1708 1709 1710 1721 1722 1725 1725 1727 1727 1731 1738 1739 1739 1741 1741 1742 1743 1745 1745 1746 1749 1749 1751 1754 1759 1759 1761 1764 1765 1766 1767 1769 1772 1772 1773 1776 1777 1778 1779 1780 1782 1782 1782 1792 1793 1798 1798 1806 1806 1808 1812 1815 1815 1816 1817 1817 1819 1819 1819 1822 1822 1823 1826 1827 1827 1828 1831 1833 1833 1836 1836 1845 1849 1850 1852 1854 1855 1855 1857 1859 1861 1862 1864 1864 1870 1876 1881 1883 1888 1888 1890 1893 1903 1904 1909 1911 1915 1920 1923 1924 1926 1926 1929 1934 1937 1937 1939 1946 1948 1949 1950 1953 1954 1955 1955 1956 1957 1959 1961 1966 1968 1974 1980 1985 1985 1986 1988 1989 1990 1992 1994 1998 1998 2000 2003 2006 2006 2007 2008 2012 2016 2018 2026 2027 2029 2036 2037 2040 2043 2043 2045 2045 2048 \n",
            "\n"
          ]
        }
      ],
      "source": [
        "%cuda_group_run --group \"source\" --compiler-args \"-O3 -g -std=c++20 -arch=sm_75\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K0Yqomwu6WsP"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}